---
title: "The Labyrinth of Links: Navigating the Associative Maze of Multi-modal LLMs"
collection: publications\
category: manuscripts
excerpt: "In this paper, we first devise a standard association benchmark based on adjective and verb association semantic concepts. Instead of costly data annotation and organization, we propose a convenient annotation-free reconstruction method transforming the general dataset for our association tasks. Furthermore, we comprehensively investigate the MLLMs's ability and potential for association ability.
[Project](https://mvig-rhos.com/llm_inception)
[Code](https://github.com/lihong2303/LLM_Inception)
[Paper](https://arxiv.org/abs/2410.01417)"
date: 2024-10-02
venue: "arXiv"
# code: "https://github.com/lihong2303/LLM_Inception"
# paperurl: "https://arxiv.org/abs/2410.01417"
# project: "https://mvig-rhos.com/llm_inception"
---
<figure>
  <img src="/images/llm_perception_teaser_figure.png" alt="Teaser figure for The Labyrinth of Links: Navigating the Associative Maze of Multi-modal LLMs" style="width:100%">
  <figcaption>Figure 1: Overview of our proposed association benchmark for Multi-modal Large Language Models (MLLMs).</figcaption>
</figure>

Multi-modal Large Language Models (MLLMs) have exhibited impressive capability. However, recently many deficiencies of MLLMs have been found compared to human intelligence, e.g., hallucination. To drive the MLLMs study, the community dedicated efforts to building larger benchmarks with complex tasks. In this paper, we propose benchmarking an essential but usually overlooked intelligence: association, a human's basic capability to link observation and prior practice memory. To comprehensively investigate MLLM's performance on the association, we formulate the association task and devise a standard benchmark based on adjective and verb semantic concepts. Instead of costly data annotation and curation, we propose a convenient annotation-free construction method transforming the general dataset for our association tasks. Simultaneously, we devise a rigorous data refinement process to eliminate confusion in the raw dataset. Building on this database, we establish three levels of association tasks: single-step, synchronous, and asynchronous associations. Moreover, we conduct a comprehensive investigation into the MLLMs' zero-shot association capabilities, addressing multiple dimensions, including three distinct memory strategies, both open-source and closed-source MLLMs, cutting-edge Mixture-of-Experts (MoE) models, and the involvement of human experts. Our systematic investigation shows that current open-source MLLMs consistently exhibit poor capability in our association tasks, even the currently state-of-the-art GPT-4V(vision) also has a significant gap compared to humans. We believe our benchmark would pave the way for future MLLM studies.

[Project](https://mvig-rhos.com/llm_inception)
[Code](https://github.com/lihong2303/LLM_Inception)
[Paper](https://arxiv.org/abs/2410.01417)
