---
title: "PRISM: Robust VLM Alignment with Principled Reasoning for Integrated Safety in Multimodality"
collection: publications
category: manuscripts
excerpt: "This paper introduces PRISM, a framework for robust alignment of Vision-Language Models (VLMs) with principled reasoning to ensure integrated safety in multimodal settings. The key challenge addressed is overdefense, which harms utility, and the balance between safety and benign performance.

[Paper](https://arxiv.org/pdf/2508.18649)

[Code](https://github.com/SaFoLab-WISC/PRISM)
"
date: 2025-08-18
venue: "arXiv"
---

Safeguarding vision-language models (VLMs) is a critical challenge, as existing methods often suffer from over-defense, which harms utility, or rely on shallow alignment, failing to detect complex threats that require deep reasoning. To this end, we introduce PRISM (Principled Reasoning for Integrated Safety in Multimodality), a system2-like framework that aligns VLMs by embedding a structured, safety-aware reasoning process. Our framework consists of two key components: PRISM-CoT, a dataset that teaches safety-aware chain-of-thought reasoning, and PRISM-DPO, generated via Monte Carlo Tree Search (MCTS) to further refine this reasoning through Direct Preference Optimization to help obtain a delicate safety boundary. Comprehensive evaluations demonstrate PRISM's effectiveness, achieving remarkably low attack success rates including 0.15% on JailbreakV-28K for Qwen2-VL and 90% improvement over the previous best method on VLBreak for LLaVA-1.5. PRISM also exhibits strong robustness against adaptive attacks, significantly increasing computational costs for adversaries, and generalizes effectively to out-of-distribution challenges, reducing attack success rates to just 8.70% on the challenging multi-image MIS benchmark. Remarkably, this robust defense is achieved while preserving, and in some cases enhancing, model utility.

[[Paper]](https://arxiv.org/pdf/2508.18649)

[[Code]](https://github.com/SaFoLab-WISC/PRISM)